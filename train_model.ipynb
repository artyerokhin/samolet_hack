{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b29177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 20:29:03 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.36                 Driver Version: 546.33       CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 30%   46C    P5              56W / 200W |   2956MiB /  8192MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A        32      G   /Xwayland                                 N/A      |\r\n",
      "|    0   N/A  N/A       808      C   /python3.8                                N/A      |\r\n",
      "|    0   N/A  N/A       907      C   /python3.8                                N/A      |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aba7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from train_utils import data_processor, most_common_words, fix_train_common, tokenize_and_align_labels, compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7593473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, RobertaTokenizerFast, DebertaV2TokenizerFast, DebertaTokenizerFast\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, RobertaForTokenClassification, DebertaV2ForTokenClassification, DebertaForTokenClassification\n",
    "from transformers import AutoModel, TrainingArguments, Trainer\n",
    "\n",
    "from transformers.trainer import logger as noisy_logger\n",
    "noisy_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81578fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1106e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = config['test_size']\n",
    "MODEL_CHECKPOINT = config['model_checkpoint']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "SEED = config['seed']\n",
    "NUM_LAYERS = config['num_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f4863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data_new.csv')\n",
    "test = pd.read_csv('gt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db12262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target_labels_positions'] = train['target_labels_positions'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0a6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_discount'] = [int('B-discount' in d.keys()) for d in train['target_labels_positions'].values]\n",
    "train['is_value'] = [int('B-value' in d.keys()) for d in train['target_labels_positions'].values]\n",
    "train['is_discount_info'] = [int('I-value' in d.keys()) for d in train['target_labels_positions'].values]\n",
    "\n",
    "# we use it for stratification\n",
    "train['label_type'] = train[['is_discount', 'is_value', 'is_discount_info']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716a642f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heuristic to filter texts with empty tags\n",
    "# we will use it later\n",
    "train[~train['processed_text'].str.contains('—Å–∫–∏–¥')]['is_discount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25965522",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOST_COMMON = most_common_words(train, 'processed_text', 'target_labels_positions', 5)\n",
    "\n",
    "# filter only most common words as labels\n",
    "# same logic, less noise -> better model\n",
    "train = fix_train_common(train, MOST_COMMON, 'processed_text', 'target_labels_positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = data_processor(train[train['processed_text'].str.contains('—Å–∫–∏–¥')], \n",
    "                                 'processed_text', 'target_labels_positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_train, ner_test = train_test_split(processed_train, test_size=TEST_SIZE, \n",
    "                                       stratify=train[train['processed_text'].str.contains('—Å–∫–∏–¥')]['label_type'], \n",
    "                                       random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c2a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df = pd.DataFrame(ner_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e4980f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 1451\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 257\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(ner_train)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(ner_test))\n",
    "})\n",
    "ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b62cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-discount', 'B-value', 'I-value']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = sorted({label for item in ner_train for label in item['tags']})\n",
    "if 'O' in label_list:\n",
    "    label_list.remove('O')\n",
    "    label_list = ['O'] + label_list\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bca84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4df3b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53662de973648a38a1176945bb2099f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1451 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4989e0253d4d41b8a89dc0c83f9775eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = ner_data.map(partial(tokenize_and_align_labels, tokenizer, label_list), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87afc984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=len(label_list))\n",
    "model.config.id2label = dict(enumerate(label_list))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d6146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ce240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1686/152412463.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/home/gofat/miniconda3/lib/python3.8/site-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adbc6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞\n",
    "for param in list(model.parameters())[-NUM_LAYERS:]:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "861f73bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gofat/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"samolet_finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model='f1',\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none',\n",
    ")\n",
    "# lr_scheduler_type='cosine',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8470f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, label_list, metric)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9da38cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3630' max='3630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3630/3630 15:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.414925</td>\n",
       "      <td>0.448387</td>\n",
       "      <td>0.431008</td>\n",
       "      <td>0.996377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.542113</td>\n",
       "      <td>0.996473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.544601</td>\n",
       "      <td>0.374194</td>\n",
       "      <td>0.443595</td>\n",
       "      <td>0.996855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.598361</td>\n",
       "      <td>0.470968</td>\n",
       "      <td>0.527076</td>\n",
       "      <td>0.997020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.585670</td>\n",
       "      <td>0.996603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.364516</td>\n",
       "      <td>0.476793</td>\n",
       "      <td>0.997124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.997133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.537459</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.534846</td>\n",
       "      <td>0.996620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.544218</td>\n",
       "      <td>0.996846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.560554</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.540902</td>\n",
       "      <td>0.996725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3630, training_loss=0.00868902132530843, metrics={'train_runtime': 918.4812, 'train_samples_per_second': 15.798, 'train_steps_per_second': 3.952, 'total_flos': 3779844331726272.0, 'train_loss': 0.00868902132530843, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c2e4a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'discount': {'precision': 0.6336206896551724,\n",
       "  'recall': 0.6150627615062761,\n",
       "  'f1': 0.624203821656051,\n",
       "  'number': 239},\n",
       " 'value': {'precision': 0.41,\n",
       "  'recall': 0.5774647887323944,\n",
       "  'f1': 0.47953216374269003,\n",
       "  'number': 71},\n",
       " 'overall_precision': 0.5662650602409639,\n",
       " 'overall_recall': 0.6064516129032258,\n",
       " 'overall_f1': 0.5856697819314642,\n",
       " 'overall_accuracy': 0.9966028949243254}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5414399",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('samolet_finetuned_{}'.format(str(round(results['overall_f1'], 2)).replace('.', '_')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ec33b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-discount</th>\n",
       "      <th>B-value</th>\n",
       "      <th>I-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>114406</td>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-discount</th>\n",
       "      <td>92</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-value</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-value</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 O  B-discount  B-value  I-value\n",
       "O           114406          85       43      126\n",
       "B-discount      92         147        0        0\n",
       "B-value         19           0       43        0\n",
       "I-value         26           0        0      111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(sum(true_labels, []), sum(true_predictions, []), labels=label_list),\n",
    "    index=label_list,\n",
    "    columns=label_list\n",
    ")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2456549d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–≤–æ—Ç —ç—ç –∑–Ω–∞–Ω–∏–µ –Ω–∞–ø–ª–µ—Ç–∞–µ—Ç –Ω–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ –º–µ—Ç—Ä—ã –∞ –æ–Ω–∞ –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ —É –≤–∞—Å –∫–æ—Ä–æ—á–µ –∏–ø–æ—Ç–µ–∫–∞ NAME –Ω–∞ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞ –ø–æ–¥—ä–µ–¥—É –¥–∞ –¥–∞ –¥–∞ –≤–∞—Ç—Å–∞–ø –æ—Ç—á–µ—Ç —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º —Ö–æ—Ä–æ—à–æ —Å–ø–∞—Å–∏–±–æ –¥–≤–∞ –¥–∞ –Ω–µ—Ç –¥–ª—è —Ç–µ–±—è —Ç—Ä–µ—Ç—å—è –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ —Ö–æ—Ç–µ–ª –∑–∞–µ—Ö–∞—Ç—å –∫ –≤–∞–º –≤ –æ—Ñ–∏—Å –Ω–∞ NAME –∞–ª–ª–æ NAME –Ω–µ ADDRESS NAME –æ—Ñ–∏—Å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —É –≤–∞—Å —É –æ—Å—Ç–∞—Ç—å—Å—è –º–Ω–µ –±–ª–∏–∂–µ –∞ –≥–¥–µ –∞ –≥–¥–µ –¥–µ–≤—è—Ç –≤ –¥–µ–≤—è—Ç –¥–µ–≤—è—Ç–∫–∏ –Ω–∞–π–¥ –∑–∞–±—ã–ª –Ω–∞–∑–≤–∞–Ω–∏–µ NAME –¥–∞ —è —Ö–æ—Ç–µ–ª –æ–±—Å—É–¥–∏—Ç—å –∏–ø–æ—Ç–µ–∫—É —É—Å–ª–æ–≤–∏—è –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å –≤ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞ –¥–∞ –∞–ª–ª–æ–¥–æ–±—Ä—ã–π –¥–µ–Ω—å —Å–∞–º–æ–ª–µ—Ç –º–µ–Ω—è –∑–æ–≤—É—Ç NAME –∫–∞–∫ –º–æ–≥—É –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –≤–∞–º –∫–∞–∫–æ–π —É –≤–∞—Å –≤–æ–ø—Ä–æ—Å –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –∫–∞–∫ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –≤–∞–º –≤–∞—à –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä –∞–∫—Ç—É–∞–ª—å–Ω–∞ –æ–∫–æ–Ω—á–∏—Ç–µ–ª—å–Ω–æ —Å–µ–º—å–¥–µ—Å—è—Ç –¥–≤–∞ —è –º–æ–≥—É –≤–∞—Å –∑–∞–ø–∏—Å–∞—Ç—å —á–µ—Ä–µ–∑ —á–∞—Å –∑–∞ –ø–æ–¥—ä–µ–∑–¥ –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Å–µ–º—å–¥–µ—Å—è—Ç –¥–≤–∞ –Ω–æ–ª—å –æ–¥–∏–Ω –∞–∫—Ç—É–∞–ª—å–Ω–æ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –º–æ–≥—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–∫–∞–∂–∏—Ç–µ –∫—É–¥–∞ –ª—É—á—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞–±—Ä–∞—Ç—å –≤–∞—Ç—Å–∞–ø –∏–ª–∏ –æ–±—ã—á–Ω–æ–µ —Å–º—Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤–∞—Ç—Å–∞–ø –æ—Ç–ª–∏—á–Ω–æ —Å–∫–∞–∂–∏—Ç–µ –ø–æ–µ–¥–µ—Ç–µ –Ω–∞–ª–∏—á–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –Ω–∞ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —Ç—Ä–∞–Ω—Å —Ö–æ—Ä–æ—à–æ —Ç–∞–∫ –∂–µ —Ö–æ—Ç–µ–ª–∞ –≤–∞–º —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ —É –≤–∞—Å –±—É–¥–µ—Ç –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ —Å–∫–∏–¥–∫–∞ –≤ –æ–¥–∏–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞ –æ–±—â–µ–Ω–∏–µ –æ—Ñ–∏—Å–∞ –∏–º–µ–Ω–Ω–æ —Å–µ–≥–æ–¥–Ω—è –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ –æ—Ñ–∏—Å –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º —Ç–æ –Ω–∞–∑–≤–∞—Ç—å —Å–≤–æ–π –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Å–µ–º—å–¥–µ—Å—è—Ç –¥–≤–∞ –Ω–æ–ª—å –æ–¥–∏–Ω –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–∫–∏–¥–∫–∏ –Ω–µ –∑–∞—Å–æ—Ä –∑–∞–ø–∏—Å–∞–ª–∞ –∏ –º–æ—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤–∞–º –≤—ã—Å–ª–∞–ª–∞ –∫–∞–∫ –¥–æ–±—Ä–∞—Ç—å—Å—è –¥–æ –æ—Ñ–∏—Å–∞ –æ–∂–∏–¥–∞–µ–º –≤–∞—Å —Å–∫–∞–∂–∏—Ç–µ –æ—Å—Ç–∞–ª–∏—Å—å –∫–æ –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –∞ –Ω–æ–ª—å –æ–¥–∏–Ω —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –¥–ª—è —Å–µ–±—è –∏–ª–∏ –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –∫–∞–∫ –∞–≥–µ–Ω—Ç –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å –≤—ã–±—Ä–∞–ª–∏ –∏–ª–∏ –µ—â–µ –Ω–µ—Ç –∞ –Ω–µ —Å–∞–º–æ–ª–µ—Ç —á–µ–º –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å –¥–∞ –¥–∞ —è –≤–∞—Å —Å–ª—ã—à—É –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –∫–∞–∫ –º–æ–≥—É –∫ –≤–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è NAME –ø—Ä–∏—è—Ç–Ω–æ NAME –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å –ª—é–±–µ—Ä—Ü—ã –ª—é–±–µ—Ä –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø –∏–∑ –¥–æ–º–∞ –º–µ—Ç—Ä–æ –Ω–µ –∫—Ä–∞—Å–æ—á–∫–∏ –∑–∞—á–µ–º –∏–º–µ–Ω–Ω–æ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º –æ–π —Ç–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å —É –≤–∞—Å —Å–º–æ—Ç—Ä–∏—Ç–µ —É –Ω–∞—Å –∫–∞–∂–¥—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –∂–∏–ª–æ–º –∫–æ–º–ø–ª–µ–∫—Å —Ç–æ –µ—Å—Ç—å –µ—Å–ª–∏ –≤—ã–±–∏—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å —Ç–æ –æ—Ñ–∏—Å –ø—Ä–æ–¥–∞–∂ –±—É–¥–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –æ—Ñ–∏—Å —É –Ω–∞—Å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –∫–∞–∫–æ–π –Ω–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–¥–Ω—É –º–∏–Ω—É—Ç—É –¥–∞ –¥–∞ —Ä—è–¥–æ–º —Å –º—É—Ä–∏–Ω–æ–º —É –Ω–∞—Å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å –Ω–æ–≤—ã–µ –ª–∞–≤—Ä–∏–∫–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–ª–∏ –≤—Å–µ –≤–µ—Ä–Ω–æ –¥–∞ –º–µ—Ç—Ä–æ –¥–µ–≤—è—Ç–∫–∏–Ω–∞ –±—É–¥–µ—Ç –≤ –ø–µ—à–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ —É–∂–µ –æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å –∂–∏–ª—ã–º –∫–æ–º–ø–ª–µ–∫—Å–æ–º –≤—Å–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å —É–∂–µ —Ö–æ—Ç–∏—Ç–µ –ø–æ–¥—ä–µ—Ö–∞—Ç—å –≤–æ–π –¥–∞ –∫–æ–Ω–µ—á–Ω–æ –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —É–¥–æ–±–Ω–æ –≤–∞–º –ø–æ–¥—ä–µ–∑–¥ —Å–µ–≥–æ–¥–Ω—è –∑–∞–≤—Ç—Ä–∞ –∫–æ–≥–¥–∞ –∑–∞–ø–∏—Å–∞–ª–∞ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å –æ–¥–Ω—É –º–∏–Ω—É—Ç—É –¥–∞ –ª–∞–¥–Ω–æ –¥–∞ –¥–∞ —Å–µ–π—á–∞—Å –æ–¥–Ω—É –º–∏–Ω—É—Ç—É –∑–∞–ø–∏—Å—ã–≤–∞–ª–∞ –Ω—É —ç—Ç–æ —Å–µ–π—á–∞—Å –¥–∞'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = ' '.join(ner_train[8]['tokens'])\n",
    "text = ' '.join(ner_test[11]['tokens'])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e202568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model, tokenizer=tokenizer, task='ner', aggregation_strategy='average', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68446421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–≤–æ—Ç —ç—ç –∑–Ω–∞–Ω–∏–µ –Ω–∞–ø–ª–µ—Ç–∞–µ—Ç –Ω–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ –º–µ—Ç—Ä—ã –∞ –æ–Ω–∞ –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ —É –≤–∞—Å –∫–æ—Ä–æ—á–µ –∏–ø–æ—Ç–µ–∫–∞ NAME –Ω–∞ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞ –ø–æ–¥—ä–µ–¥—É –¥–∞ –¥–∞ –¥–∞ –≤–∞—Ç—Å–∞–ø –æ—Ç—á–µ—Ç —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º —Ö–æ—Ä–æ—à–æ —Å–ø–∞—Å–∏–±–æ –¥–≤–∞ –¥–∞ –Ω–µ—Ç –¥–ª—è —Ç–µ–±—è —Ç—Ä–µ—Ç—å—è –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ —Ö–æ—Ç–µ–ª –∑–∞–µ—Ö–∞—Ç—å –∫ –≤–∞–º –≤ –æ—Ñ–∏—Å –Ω–∞ NAME –∞–ª–ª–æ NAME –Ω–µ ADDRESS NAME –æ—Ñ–∏—Å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —É –≤–∞—Å —É –æ—Å—Ç–∞—Ç—å—Å—è –º–Ω–µ –±–ª–∏–∂–µ –∞ –≥–¥–µ –∞ –≥–¥–µ –¥–µ–≤—è—Ç –≤ –¥–µ–≤—è—Ç –¥–µ–≤—è—Ç–∫–∏ –Ω–∞–π–¥ –∑–∞–±—ã–ª –Ω–∞–∑–≤–∞–Ω–∏–µ NAME –¥–∞ —è —Ö–æ—Ç–µ–ª –æ–±—Å—É–¥–∏—Ç—å –∏–ø–æ—Ç–µ–∫—É —É—Å–ª–æ–≤–∏—è –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å –≤ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞ –¥–∞ –∞–ª–ª–æ–¥–æ–±—Ä—ã–π –¥–µ–Ω—å —Å–∞–º–æ–ª–µ—Ç –º–µ–Ω—è –∑–æ–≤—É—Ç NAME –∫–∞–∫ –º–æ–≥—É –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –≤–∞–º –∫–∞–∫–æ–π —É –≤–∞—Å –≤–æ–ø—Ä–æ—Å –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –∫–∞–∫ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –≤–∞–º –≤–∞—à –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä –∞–∫—Ç—É–∞–ª—å–Ω–∞ –æ–∫–æ–Ω—á–∏—Ç–µ–ª—å–Ω–æ —Å–µ–º—å–¥–µ—Å—è—Ç –¥–≤–∞ —è –º–æ–≥—É –≤–∞—Å –∑–∞–ø–∏—Å–∞—Ç—å —á–µ—Ä–µ–∑ —á–∞—Å –∑–∞ –ø–æ–¥—ä–µ–∑–¥ –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Å–µ–º—å–¥–µ—Å—è—Ç –¥–≤–∞ –Ω–æ–ª—å –æ–¥–∏–Ω –∞–∫—Ç—É–∞–ª—å–Ω–æ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –º–æ–≥—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–∫–∞–∂–∏—Ç–µ –∫—É–¥–∞ –ª—É—á—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞–±—Ä–∞—Ç—å –≤–∞—Ç—Å–∞–ø –∏–ª–∏ –æ–±—ã—á–Ω–æ–µ —Å–º—Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤–∞—Ç—Å–∞–ø –æ—Ç–ª–∏—á–Ω–æ —Å–∫–∞–∂–∏—Ç–µ –ø–æ–µ–¥–µ—Ç–µ –Ω–∞–ª–∏—á–Ω—ã–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—å –Ω–∞ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —Ç—Ä–∞–Ω—Å —Ö–æ—Ä–æ—à–æ —Ç–∞–∫ –∂–µ —Ö–æ—Ç–µ–ª–∞ –≤–∞–º —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ —É –≤–∞—Å –±—É–¥–µ—Ç –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ —Å–∫–∏–¥–∫–∞ –≤ –æ–¥–∏–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞ –æ–±—â–µ–Ω–∏–µ –æ—Ñ–∏—Å–∞ –∏–º–µ–Ω–Ω–æ —Å–µ–≥–æ–¥–Ω—è –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ –æ—Ñ–∏—Å –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º —Ç–æ –Ω–∞–∑–≤–∞—Ç—å —Å–≤–æ–π –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Å–µ–º—å–¥–µ—Å—è—Ç –¥–≤–∞ –Ω–æ–ª—å –æ–¥–∏–Ω –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–∫–∏–¥–∫–∏ –Ω–µ –∑–∞—Å–æ—Ä –∑–∞–ø–∏—Å–∞–ª–∞ –∏ –º–æ—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤–∞–º –≤—ã—Å–ª–∞–ª–∞ –∫–∞–∫ –¥–æ–±—Ä–∞—Ç—å—Å—è –¥–æ –æ—Ñ–∏—Å–∞ –æ–∂–∏–¥–∞–µ–º –≤–∞—Å —Å–∫–∞–∂–∏—Ç–µ –æ—Å—Ç–∞–ª–∏—Å—å –∫–æ –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –∞ –Ω–æ–ª—å –æ–¥–∏–Ω —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ –¥–ª—è —Å–µ–±—è –∏–ª–∏ –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –∫–∞–∫ –∞–≥–µ–Ω—Ç –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å –≤—ã–±—Ä–∞–ª–∏ –∏–ª–∏ –µ—â–µ –Ω–µ—Ç –∞ –Ω–µ —Å–∞–º–æ–ª–µ—Ç —á–µ–º –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å –¥–∞ –¥–∞ —è –≤–∞—Å —Å–ª—ã—à—É –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –∫–∞–∫ –º–æ–≥—É –∫ –≤–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è NAME –ø—Ä–∏—è—Ç–Ω–æ NAME –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å –ª—é–±–µ—Ä—Ü—ã –ª—é–±–µ—Ä –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø –∏–∑ –¥–æ–º–∞ –º–µ—Ç—Ä–æ –Ω–µ –∫—Ä–∞—Å–æ—á–∫–∏ –∑–∞—á–µ–º –∏–º–µ–Ω–Ω–æ –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º –æ–π —Ç–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å —É –≤–∞—Å —Å–º–æ—Ç—Ä–∏—Ç–µ —É –Ω–∞—Å –∫–∞–∂–¥—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –∂–∏–ª–æ–º –∫–æ–º–ø–ª–µ–∫—Å —Ç–æ –µ—Å—Ç—å –µ—Å–ª–∏ –≤—ã–±–∏—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å —Ç–æ –æ—Ñ–∏—Å –ø—Ä–æ–¥–∞–∂ –±—É–¥–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –æ—Ñ–∏—Å —É –Ω–∞—Å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –∫–∞–∫–æ–π –Ω–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–¥–Ω—É –º–∏–Ω—É—Ç—É –¥–∞ –¥–∞ —Ä—è–¥–æ–º —Å –º—É—Ä–∏–Ω–æ–º —É –Ω–∞—Å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å –Ω–æ–≤—ã–µ –ª–∞–≤—Ä–∏–∫–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–ª–∏ –≤—Å–µ –≤–µ—Ä–Ω–æ –¥–∞ –º–µ—Ç—Ä–æ –¥–µ–≤—è—Ç–∫–∏–Ω–∞ –±—É–¥–µ—Ç –≤ –ø–µ—à–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ —É–∂–µ –æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å –∂–∏–ª—ã–º –∫–æ–º–ø–ª–µ–∫—Å–æ–º –≤—Å–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å —É–∂–µ —Ö–æ—Ç–∏—Ç–µ –ø–æ–¥—ä–µ—Ö–∞—Ç—å –≤–æ–π –¥–∞ –∫–æ–Ω–µ—á–Ω–æ –ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —É–¥–æ–±–Ω–æ –≤–∞–º –ø–æ–¥—ä–µ–∑–¥ —Å–µ–≥–æ–¥–Ω—è –∑–∞–≤—Ç—Ä–∞ –∫–æ–≥–¥–∞ –∑–∞–ø–∏—Å–∞–ª–∞ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å –æ–¥–Ω—É –º–∏–Ω—É—Ç—É –¥–∞ –ª–∞–¥–Ω–æ –¥–∞ –¥–∞ —Å–µ–π—á–∞—Å –æ–¥–Ω—É –º–∏–Ω—É—Ç—É –∑–∞–ø–∏—Å—ã–≤–∞–ª–∞ –Ω—É —ç—Ç–æ —Å–µ–π—á–∞—Å –¥–∞\n",
      "[{'entity_group': 'discount', 'score': 0.624862, 'word': '—Å–∫–∏–¥–∫–∞', 'start': 949, 'end': 955}, {'entity_group': 'value', 'score': 0.8235737, 'word': '–æ–¥–∏–Ω –ø—Ä–æ—Ü–µ–Ω—Ç', 'start': 958, 'end': 970}]\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(pipe(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
