{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b29177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 20:29:03 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.36                 Driver Version: 546.33       CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 30%   46C    P5              56W / 200W |   2956MiB /  8192MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A        32      G   /Xwayland                                 N/A      |\r\n",
      "|    0   N/A  N/A       808      C   /python3.8                                N/A      |\r\n",
      "|    0   N/A  N/A       907      C   /python3.8                                N/A      |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aba7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from train_utils import data_processor, most_common_words, fix_train_common, tokenize_and_align_labels, compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7593473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, RobertaTokenizerFast, DebertaV2TokenizerFast, DebertaTokenizerFast\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, RobertaForTokenClassification, DebertaV2ForTokenClassification, DebertaForTokenClassification\n",
    "from transformers import AutoModel, TrainingArguments, Trainer\n",
    "\n",
    "from transformers.trainer import logger as noisy_logger\n",
    "noisy_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81578fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\") as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1106e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = config['test_size']\n",
    "MODEL_CHECKPOINT = config['model_checkpoint']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "SEED = config['seed']\n",
    "NUM_LAYERS = config['num_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f4863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data_new.csv')\n",
    "test = pd.read_csv('gt_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db12262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target_labels_positions'] = train['target_labels_positions'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0a6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_discount'] = [int('B-discount' in d.keys()) for d in train['target_labels_positions'].values]\n",
    "train['is_value'] = [int('B-value' in d.keys()) for d in train['target_labels_positions'].values]\n",
    "train['is_discount_info'] = [int('I-value' in d.keys()) for d in train['target_labels_positions'].values]\n",
    "\n",
    "# we use it for stratification\n",
    "train['label_type'] = train[['is_discount', 'is_value', 'is_discount_info']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716a642f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heuristic to filter texts with empty tags\n",
    "# we will use it later\n",
    "train[~train['processed_text'].str.contains('скид')]['is_discount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25965522",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOST_COMMON = most_common_words(train, 'processed_text', 'target_labels_positions', 5)\n",
    "\n",
    "# filter only most common words as labels\n",
    "# same logic, less noise -> better model\n",
    "train = fix_train_common(train, MOST_COMMON, 'processed_text', 'target_labels_positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = data_processor(train[train['processed_text'].str.contains('скид')], \n",
    "                                 'processed_text', 'target_labels_positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_train, ner_test = train_test_split(processed_train, test_size=TEST_SIZE, \n",
    "                                       stratify=train[train['processed_text'].str.contains('скид')]['label_type'], \n",
    "                                       random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c2a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df = pd.DataFrame(ner_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e4980f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 1451\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 257\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(ner_train)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(ner_test))\n",
    "})\n",
    "ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b62cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-discount', 'B-value', 'I-value']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = sorted({label for item in ner_train for label in item['tags']})\n",
    "if 'O' in label_list:\n",
    "    label_list.remove('O')\n",
    "    label_list = ['O'] + label_list\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bca84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, model_max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4df3b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53662de973648a38a1176945bb2099f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1451 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4989e0253d4d41b8a89dc0c83f9775eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = ner_data.map(partial(tokenize_and_align_labels, tokenizer, label_list), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87afc984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=len(label_list))\n",
    "model.config.id2label = dict(enumerate(label_list))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d6146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ce240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1686/152412463.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "/home/gofat/miniconda3/lib/python3.8/site-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adbc6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разморозка\n",
    "for param in list(model.parameters())[-NUM_LAYERS:]:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "861f73bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gofat/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"samolet_finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model='f1',\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none',\n",
    ")\n",
    "# lr_scheduler_type='cosine',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8470f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, label_list, metric)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9da38cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3630' max='3630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3630/3630 15:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.414925</td>\n",
       "      <td>0.448387</td>\n",
       "      <td>0.431008</td>\n",
       "      <td>0.996377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.542113</td>\n",
       "      <td>0.996473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.544601</td>\n",
       "      <td>0.374194</td>\n",
       "      <td>0.443595</td>\n",
       "      <td>0.996855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.598361</td>\n",
       "      <td>0.470968</td>\n",
       "      <td>0.527076</td>\n",
       "      <td>0.997020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.585670</td>\n",
       "      <td>0.996603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.364516</td>\n",
       "      <td>0.476793</td>\n",
       "      <td>0.997124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.997133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.537459</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.534846</td>\n",
       "      <td>0.996620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.544218</td>\n",
       "      <td>0.996846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.560554</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.540902</td>\n",
       "      <td>0.996725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3630, training_loss=0.00868902132530843, metrics={'train_runtime': 918.4812, 'train_samples_per_second': 15.798, 'train_steps_per_second': 3.952, 'total_flos': 3779844331726272.0, 'train_loss': 0.00868902132530843, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c2e4a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'discount': {'precision': 0.6336206896551724,\n",
       "  'recall': 0.6150627615062761,\n",
       "  'f1': 0.624203821656051,\n",
       "  'number': 239},\n",
       " 'value': {'precision': 0.41,\n",
       "  'recall': 0.5774647887323944,\n",
       "  'f1': 0.47953216374269003,\n",
       "  'number': 71},\n",
       " 'overall_precision': 0.5662650602409639,\n",
       " 'overall_recall': 0.6064516129032258,\n",
       " 'overall_f1': 0.5856697819314642,\n",
       " 'overall_accuracy': 0.9966028949243254}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5414399",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('samolet_finetuned_{}'.format(str(round(results['overall_f1'], 2)).replace('.', '_')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ec33b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-discount</th>\n",
       "      <th>B-value</th>\n",
       "      <th>I-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>114406</td>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-discount</th>\n",
       "      <td>92</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-value</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-value</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 O  B-discount  B-value  I-value\n",
       "O           114406          85       43      126\n",
       "B-discount      92         147        0        0\n",
       "B-value         19           0       43        0\n",
       "I-value         26           0        0      111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(sum(true_labels, []), sum(true_predictions, []), labels=label_list),\n",
    "    index=label_list,\n",
    "    columns=label_list\n",
    ")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2456549d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вот ээ знание наплетает на квадратные метры а она говорит что у вас короче ипотека NAME на течение часа подъеду да да да ватсап отчет с оператором хорошо спасибо два да нет для тебя третья здравствуйте хотел заехать к вам в офис на NAME алло NAME не ADDRESS NAME офис центральный у вас у остаться мне ближе а где а где девят в девят девятки найд забыл название NAME да я хотел обсудить ипотеку условия прямо сейчас в течение часа да аллодобрый день самолет меня зовут NAME как могу обращаться к вам какой у вас вопрос подскажите как обращаться к вам ваш контактный номер актуальна окончительно семьдесят два я могу вас записать через час за подъезд подскажите номер телефона семьдесят два ноль один актуально номер телефона могу информацию скажите куда лучше информацию набрать ватсап или обычное смс уведомления ватсап отлично скажите поедете наличные автомобиль на общественном транс хорошо так же хотела вам сказать что у вас будет гарантирована скидка в один процент за общение офиса именно сегодня при входе в офис нужно будет администратором то назвать свой номер телефона семьдесят два ноль один для подтверждения скидки не засор записала и мощу информацию вам выслала как добраться до офиса ожидаем вас скажите остались ко мне вопросы а ноль один рассматривайте для себя или обращайтесь к как агент жилой комплекс выбрали или еще нет а не самолет чем могу вам помочь да да я вас слышу подскажите как могу к вам обращаться NAME приятно NAME жилой комплекс люберцы любер если доступ из дома метро не красочки зачем именно в центральном ой такой вопрос у вас смотрите у нас каждый менеджер консультирует на жилом комплекс то есть если выбирать конкретно жилой комплекс то офис продаж будет конкретный а центральный офис у нас не принимается клиентов какой новый комплекс рассматриваете название одну минуту да да рядом с мурином у нас находится жилой комплекс новые лаврики рассматривали все верно да метро девяткина будет в пешей доступности подскажите уже ознакомились с жилым комплексом все понравилось уже хотите подъехать вой да конечно подскажите когда будет удобно вам подъезд сегодня завтра когда записала прямо сейчас одну минуту да ладно да да сейчас одну минуту записывала ну это сейчас да'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = ' '.join(ner_train[8]['tokens'])\n",
    "text = ' '.join(ner_test[11]['tokens'])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e202568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model, tokenizer=tokenizer, task='ner', aggregation_strategy='average', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68446421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот ээ знание наплетает на квадратные метры а она говорит что у вас короче ипотека NAME на течение часа подъеду да да да ватсап отчет с оператором хорошо спасибо два да нет для тебя третья здравствуйте хотел заехать к вам в офис на NAME алло NAME не ADDRESS NAME офис центральный у вас у остаться мне ближе а где а где девят в девят девятки найд забыл название NAME да я хотел обсудить ипотеку условия прямо сейчас в течение часа да аллодобрый день самолет меня зовут NAME как могу обращаться к вам какой у вас вопрос подскажите как обращаться к вам ваш контактный номер актуальна окончительно семьдесят два я могу вас записать через час за подъезд подскажите номер телефона семьдесят два ноль один актуально номер телефона могу информацию скажите куда лучше информацию набрать ватсап или обычное смс уведомления ватсап отлично скажите поедете наличные автомобиль на общественном транс хорошо так же хотела вам сказать что у вас будет гарантирована скидка в один процент за общение офиса именно сегодня при входе в офис нужно будет администратором то назвать свой номер телефона семьдесят два ноль один для подтверждения скидки не засор записала и мощу информацию вам выслала как добраться до офиса ожидаем вас скажите остались ко мне вопросы а ноль один рассматривайте для себя или обращайтесь к как агент жилой комплекс выбрали или еще нет а не самолет чем могу вам помочь да да я вас слышу подскажите как могу к вам обращаться NAME приятно NAME жилой комплекс люберцы любер если доступ из дома метро не красочки зачем именно в центральном ой такой вопрос у вас смотрите у нас каждый менеджер консультирует на жилом комплекс то есть если выбирать конкретно жилой комплекс то офис продаж будет конкретный а центральный офис у нас не принимается клиентов какой новый комплекс рассматриваете название одну минуту да да рядом с мурином у нас находится жилой комплекс новые лаврики рассматривали все верно да метро девяткина будет в пешей доступности подскажите уже ознакомились с жилым комплексом все понравилось уже хотите подъехать вой да конечно подскажите когда будет удобно вам подъезд сегодня завтра когда записала прямо сейчас одну минуту да ладно да да сейчас одну минуту записывала ну это сейчас да\n",
      "[{'entity_group': 'discount', 'score': 0.624862, 'word': 'скидка', 'start': 949, 'end': 955}, {'entity_group': 'value', 'score': 0.8235737, 'word': 'один процент', 'start': 958, 'end': 970}]\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(pipe(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
