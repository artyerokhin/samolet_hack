# Хакатон Лидеры Цифровой Трансформации
## Кейс компании самолет

### Задача

Требуется решить задачу NER (распознавание именованных сущностей) для поиска двух сущностей (одна из которых имеет две подсущности): упоминание скидки и размер скидки (в случае, если размер скидки не умещается в одно слово, используется дополнительная сущность)

### Данные

Транскрипции разговоров (запись, переведенная в текст) представлены отдельно для каждого участника: как правило, это канал оператора, но могут встречаться и диалоги с двумя каналами.

Объем данных для обучения:
- Набор включает 3400 уникальных транскрипций.
- Формат разметки: Тексты аннотированы позициями ключевых сущностей, связанных со скидками.

__Ниже приведен пример транскрибированного текста с соответствующими лейблами:__
>     'алло [Name] здравствуйте не отвлекаю сильно я вот по поводу клиента я от компании макспозвоню есть клиентка у ни е семь миллионов вот я у вас на сайте нашел в корпусе девятнадцатом есть вот трилота плюс минус подходящий по цене а с отделкой но если ползунки выключить оставить только отделку там без мебели декора там вот что то в районе четыре двести четыре триста выходит хотел узнать вообще получится докрутить ой ой семь семь двести семь триста простите скидку какой то дополнительной обещали не получится подключить так если будет три процента я включаю кухню и от этого отнимаю три процента сейчас от такой цены и больше там вообще не двигателе просто у нее вот уже насколько я знаю бро в другом проекте жалоб переориентировать на час он мне слово понравился я понял то есть уже я понялалло добрый сша нет такого такого не может быть чтоб четыре двести четыре снять такая цно не получится а ну в районе это стоимости да примерно получится если будет кухня то будет скидка три процента если кухни не будет то без скидок продается карта кухня без техники да да все верно да нет никак ну это самый дешевый вариант поэтому аа сейчас извините аа соответственно это самый дешевый вариант дешевый корпус в котором и так скидок уже за то что самая низкая максимально стика три процента то есть это и так самая самые дешевые и там сложело да'

Лейблы:
> {
  'B-discount': [168, 211],
  'B-value': [169, 220],
  'I-value': [170, 221]
}

### Решение:
1. Предварительно отфильтрованы все обучающие данные, в которых содержится подстрока 'скид' (замечено, что отсутствие такой строки в трейне в 100% случаев означает отсутствие меток);
2. Отфильтрованы редкие слова в разметке (вводится предлопожение о шуме в разметке, который можно компенсировать очисткой лейблов от редких слов);
3. Обучена модель **bert-base-multilingual-cased** (она имела наилучшее качество на выделенном тестовом наборе);
4. Создан API для POST запросов (формат можно посмотреть в swagger по адресу http://127.0.0.1:8000/docs при запуске, как описано ниже);
5. Для обучения модели и предсказания лейблов для тестового файла, созданы два jupyter notebook'а (train_model.ipynb и predict.ipynb).

### Примечания:
1. Модель скачивается во время запуска контейнера. Если нужно заранее скачать модель, она доступна по [ссылке](https://drive.google.com/drive/folders/1zX0YY_u9cO-fCP-HYOMF0FIcaSb5jMdU?usp=sharing);
2. Качество рассматривалось по f1-macro. Лучшая модель показала 0.59-0.6 f1. Альтернативы, вида cointegrated/rubert-tiny2 и deepvk/deberta-v1-distill показали качество ~0.5 и ~0.53-0.55 соответственно;
3. Валидация проводилась стратифицированным разбиением на train и test исходного обучающего множества (стратификация шла по количеству уникальных типов меток);
4. Скорость работы решения ~6 текстов в секунду на CPU.

### Запуск решения:
1. Клонируете репозиторий с помощью git clone;
2. Заходите в корневую папку;
3. Выполняете команду ```
sudo docker build . -t samolet
```;
4. Выполняете команду ```
docker run -p 8000:8000 samolet
```;
5. Решение начнет работу на localhost на 8000 порте